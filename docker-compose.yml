version: '3.8'

services:
  # Laravel API service (Task Scheduling & API Management)
  laravel:
    build:
      context: ./laravel_api
      dockerfile: Dockerfile
    image: laravel_api_image
    ports:
      - "8000:80" # Map host port 8000 to container port 80 (Nginx)
    volumes:
      - ./laravel_api:/var/www/html
    depends_on:
      - fastapi_crawler # Laravel calls FastAPI gRPC
      - redis # For session, cache etc.
      # Defaulting to PostgreSQL. Uncomment 'mongodb' if that's your choice.
      - postgresql
      # - mongodb
    networks:
      - crawler_network
    environment:
      APP_NAME: LaravelCrawler
      APP_ENV: local
      # APP_KEY will be generated by Dockerfile now, no need to set here unless for override
      APP_DEBUG: true
      APP_URL: http://localhost:8000

      LOG_CHANNEL: stack
      LOG_LEVEL: debug

      # --- DATABASE CONNECTION (PostgreSQL enabled by default) ---
      DB_CONNECTION: pgsql
      DB_HOST: pgbouncer # Connect to pgbouncer for pooled connections
      DB_PORT: 6432      # PgBouncer's default port
      DB_DATABASE: crawler_db
      DB_USERNAME: user
      DB_PASSWORD: password

      # MongoDB Configuration (uncomment if using MongoDB, and ensure jenssegers/laravel-mongodb)
      # DB_CONNECTION: mongodb
      # DB_HOST: mongodb
      # DB_PORT: 27017
      # DB_DATABASE: crawler_db
      # DB_USERNAME: null
      # DB_PASSWORD: null

      REDIS_HOST: redis
      REDIS_PASSWORD: null
      REDIS_PORT: 6379

      FASTAPI_GRPC_HOST: fastapi_crawler:50051 # Target for Laravel's gRPC calls
    
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/health"] # Simple health check for Nginx/PHP-FPM
      interval: 30s
      timeout: 10s
      retries: 5

  # FastAPI Crawler Core service (Asynchronous HTTP requests & gRPC server)
  fastapi_crawler:
    build:
      context: ./fastapi_crawler
      dockerfile: Dockerfile
    image: fastapi_crawler_image
    ports:
      - "8001:8000" # FastAPI HTTP port for health/metrics (mapped to 8001 on host to avoid conflict with Laravel 8000)
      - "50051:50051" # gRPC port
    volumes:
      - ./fastapi_crawler:/app
    depends_on:
      - redis # For proxy pool, URL deduplication
    networks:
      - crawler_network
    environment:
      REDIS_HOST: redis
      REDIS_PORT: 6379
      CAPTCHA_API_KEY: your_2captcha_api_key # Uncomment and set if using CAPTCHA solving
      PROXY_API_URL: http://example.com/api/proxies # Replace with your actual proxy API endpoint
      PROXY_UPDATE_INTERVAL_SECONDS: 3600 # Interval for proxy manager to update proxies (in seconds)
    
    # Run FastAPI with Gunicorn + Uvicorn workers for better performance
    # Increased workers to 8 for higher QPS potential on a single node
    command: gunicorn -k uvicorn.workers.UvicornWorker -w 8 main:app_rest --bind 0.0.0.0:8000
    # Health check for FastAPI's HTTP endpoint
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 20s # Give it time to start

  # Redis Master service (for task queue, proxy pool, URL deduplication)
  redis:
    image: redis:7.0-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes # Enable AOF persistence
    networks:
      - crawler_network
    healthcheck: # Basic health check for Redis
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5

  # Redis Replica (Optional: for read scalability and high availability)
  redis-replica:
    image: redis:7.0-alpine
    command: redis-server --slaveof redis 6379 --appendonly yes
    volumes:
      - redis_replica_data:/data
    depends_on:
    - redis
    networks:
      - crawler_network
    healthcheck:
      test: ["CMD", "redis-cli", "-h", "localhost", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5

  # Celery Worker service (Distributed Task Execution - scale this to meet QPS targets)
  celery_worker:
    build:
      context: ./celery_workers
      dockerfile: Dockerfile
    image: celery_worker_image
    # Increased concurrency to 300 and using gevent for better I/O concurrency.
    command: celery -A celery_app worker --loglevel=info --concurrency=300 -P gevent # Changed to gevent
    volumes:
      - ./celery_workers:/app
    depends_on:
      - redis
      - pgbouncer # Celery connects to pgbouncer for pooled PostgreSQL connections
      # - mongodb    # Uncomment for MongoDB
    networks:
      - crawler_network
    environment:
      REDIS_HOST: redis
      REDIS_PORT: 6379
      # --- DATABASE URL FOR CELERY WORKERS (PostgreSQL enabled by default) ---
      POSTGRES_URL: "postgresql://user:password@pgbouncer:6432/crawler_db" # Connect to pgbouncer
      # MONGODB_URL: mongodb://mongodb:27017 # Uncomment for MongoDB

  # PostgreSQL Data Storage service (enabled by default)
  postgresql:
    image: postgres:15-alpine
    environment:
      POSTGRES_DB: crawler_db
      POSTGRES_USER: user
      POSTGRES_PASSWORD: password
    volumes:
      - postgresql_data:/var/lib/postgresql/data
    networks:
      - crawler_network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U user -d crawler_db"]
      interval: 5s
      timeout: 5s
      retries: 5

  # PgBouncer for PostgreSQL Connection Pooling (enabled by default)
  pgbouncer:
    image: edoburu/pgbouncer
    ports:
      - "6432:6432" # PgBouncer's default port
    environment:
      - DB_HOST=postgresql
      - DB_USER=user
      - DB_PASSWORD=password
      - DB_NAME=crawler_db
      - POOL_MODE=transaction # Or 'session' depending on your app's needs
      - MAX_CLIENT_CONN=1000 # Max connections allowed to pgbouncer
      - DEFAULT_POOL_SIZE=50 # Default pool size
    depends_on:
      - postgresql
    networks:
      - crawler_network
    healthcheck:
      test: ["CMD", "bash", "-c", "echo 'show pools;' | nc -w 1 localhost 6432"]
      interval: 10s
      timeout: 5s
      retries: 5

  # MongoDB Data Storage service (alternative, uncomment if used)
  # mongodb:
  #   image: mongo:6.0
  #   ports:
  #     - "27017:27017"
  #   environment:
  #     MONGO_INITDB_DATABASE: crawler_db
  #   volumes:
  #     - mongodb_data:/data/db
  #   networks:
  #     - crawler_network
  #   healthcheck:
  #     test: ["CMD-SHELL", "mongosh --eval 'db.adminCommand(\"ping\")'"]
  #     interval: 5s
  #     timeout: 5s
  #     retries: 5

  # Optional: Monitoring with Prometheus and Grafana
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
    ports:
      - "9090:9090"
    networks:
      - crawler_network
    command: --config.file=/etc/prometheus/prometheus.yml --web.enable-remote-write-receiver --web.enable-lifecycle
    depends_on:
      - fastapi_crawler # FastAPI exposes metrics
      - redis_exporter  # Prometheus scrapes redis_exporter
      - postgres_exporter # Prometheus scrapes postgres_exporter
      # - celery_flower # Prometheus can scrape Celery Flower if it exposes metrics
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9090/-/healthy"]
      interval: 10s
      timeout: 5s
      retries: 5

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    volumes:
      - grafana_data:/var/lib/grafana
    ports:
      - "3000:3000"
    networks:
      - crawler_network
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
    depends_on:
      - prometheus # Grafana uses Prometheus as data source
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/api/health"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Exporters for Prometheus (enabled by default)
  redis_exporter:
    image: oliver006/redis_exporter
    environment:
      - REDIS_ADDR=redis:6379
    ports:
      - "9121:9121"
    networks:
      - crawler_network
    depends_on:
      - redis

  postgres_exporter:
    image: prometheuscommunity/postgres-exporter
    environment:
      - DATA_SOURCE_NAME=postgresql://user:password@postgresql:5432/crawler_db?sslmode=disable
    ports:
      - "9187:9187"
    networks:
      - crawler_network
    depends_on:
      - postgresql

  # Celery Flower for monitoring Celery tasks (enabled by default)
  celery_flower:
    build:
      context: ./celery_workers
      dockerfile: Dockerfile
    image: celery_worker_image # Use the same image as worker
    command: celery -A celery_app flower --port=5555 --broker=redis://redis:6379/0 --result_backend=redis://redis:6379/1
    ports:
      - "5555:5555"
    depends_on:
      - redis
      - celery_worker
    networks:
      - crawler_network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5555/dashboard"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Optional: ELK Stack for Centralized Logging (uncomment if needed)
  # elasticsearch:
  #   image: elasticsearch:8.8.0
  #   environment:
  #     - discovery.type=single-node
  #     - xpack.security.enabled=false # For simplicity, disable security in dev. Enable in prod.
  #     - ES_JAVA_OPTS="-Xms512m -Xmx512m" # Adjust memory
  #   ports:
  #     - "9200:9200"
  #     - "9300:9300"
  #   volumes:
  #     - elasticsearch_data:/usr/share/elasticsearch/data
  #   networks:
  #     - crawler_network
  #   healthcheck:
  #     test: ["CMD-SHELL", "curl -s http://localhost:9200/_cluster/health | grep -q '\"status\":\"green\"\\|\\\"status\":\"yellow\"'"]
  #     interval: 10s
  #     timeout: 5s
  #     retries: 10

  # logstash:
  #   image: logstash:8.8.0
  #   volumes:
  #     - ./monitoring/logstash.conf:/usr/share/logstash/pipeline/logstash.conf
  #   depends_on:
  #     - elasticsearch
  #   ports:
  #     - "5000:5000/tcp" # For Beats input
  #     - "5044:5044" # For Filebeat input
  #   networks:
  #     - crawler_network

  # kibana:
  #   image: kibana:8.8.0
  #   ports:
  #     - "5601:5601"
  #   depends_on:
  #     - elasticsearch
  #   networks:
  #     - crawler_network

networks:
  crawler_network:
    driver: bridge

volumes:
  redis_data:
  redis_replica_data:
  postgresql_data:
  mongodb_data:
  grafana_data:
  elasticsearch_data: # For ELK Stack
